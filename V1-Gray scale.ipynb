{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = '../data/train.p'\n",
    "validation_file='../data/valid.p'\n",
    "testing_file = '../data/test.p'\n",
    "labels_file = 'signnames.csv'\n",
    "\n",
    "input_file = csv.DictReader(open(labels_file))\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "with open(labels_file, mode='r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    labels_to_text = {int(rows[0]):rows[1] for rows in reader}\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_validation, y_validation = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "# Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "#  Number of validation examples\n",
    "n_validation = len(X_validation)\n",
    "\n",
    "#  Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "#  How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(labels_to_text)\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n, bins, patches = plt.hist(y_train, 43, density=0, edgecolor='black', linewidth=1)\n",
    "plt.grid(True)\n",
    "plt.title('Distribution of training classes before adding fake data')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-815cf499016a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# add generated data to the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_train_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_train_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4526\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4527\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4528\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# generate fake random training data\n",
    "max_count = max(n)\n",
    "\n",
    "new_train_x = []\n",
    "new_train_y = []\n",
    "for i in range(0, len(X_train)):\n",
    "    label = y_train[i]\n",
    "    number_of_img_to_add = math.floor(max_count * 2/n[label]) - 1    \n",
    "    for t in range(0, number_of_img_to_add):\n",
    "        # rotate -/+ 15 deg        \n",
    "        rot_angle = random.randint(-15,15)\n",
    "        M = cv2.getRotationMatrix2D((16,16),rot_angle,1)\n",
    "        dst = cv2.warpAffine(X_train[i],M,(32,32))\n",
    "        \n",
    "        # shift horizontally and vertically -/+ 2 pixels \n",
    "        dst = np.roll(dst, random.randint(-2,2), axis=0)\n",
    "        dst = np.roll(dst, random.randint(-2,2), axis=1)\n",
    "        \n",
    "        new_train_x.append(dst)\n",
    "        new_train_y.append(label)\n",
    "\n",
    "# add generated data to the training set\n",
    "X_train = np.append(X_train, new_train_x, axis=0)\n",
    "y_train = np.append(y_train, new_train_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess image - convert to grayscale and normalize\n",
    "def preprocess(img):\n",
    "    return normalize_image(grayscale(img))\n",
    "\n",
    "def grayscale(img):\n",
    "    gr = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)   \n",
    "    #gr = cv2.extractChannel(cv2.cvtColor(img, cv2.COLOR_RGB2YUV), 0)\n",
    "    return np.atleast_3d(gr)\n",
    "\n",
    "def normalize_image(image_data):\n",
    "    a = 0\n",
    "    b = 1\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "X_train = [preprocess(x) for x in X_train]\n",
    "X_validation = [preprocess(x) for x in X_validation]\n",
    "X_test = [preprocess(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training data.\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "rate = 0.001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "KEEP_PROB = 0.25\n",
    "TARGET_ACCURACY = 0.965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):        \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "\n",
    "    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    fc0 = flatten(conv2)    \n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 250.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 250), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(250))\n",
    "    fc1 = tf.matmul(fc0, fc1_W) + fc1_b    \n",
    "    # Activation.\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # Dropout layer\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # Layer 4: Fully Connected. Input = 250. Output = 160.\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(250, 160), mean = mu, stddev = sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(160))\n",
    "    fc2 = tf.matmul(fc1, fc2_W) + fc2_b    \n",
    "    # Activation.\n",
    "    fc2 = tf.nn.relu(fc2)            \n",
    "    \n",
    "    # Layer 5: Fully Connected. Input = 160. Output = 84.\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(160, 84), mean = mu, stddev = sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(84))\n",
    "    fc3 = tf.matmul(fc2, fc3_W) + fc3_b      \n",
    "    # Activation.\n",
    "    fc3 = tf.nn.relu(fc3)\n",
    "    \n",
    "    # Layer 6: Fully Connected. Input = 84. Output = 43.\n",
    "    fc4_W = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc4_b = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc3, fc4_W) + fc4_b  \n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-fa593724899f>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Accuracy: Training 0.779 / Validation = 0.792\n",
      "\n",
      "EPOCH 2 ...\n",
      "Accuracy: Training 0.900 / Validation = 0.906\n",
      "\n",
      "EPOCH 3 ...\n",
      "Accuracy: Training 0.932 / Validation = 0.935\n",
      "\n",
      "EPOCH 4 ...\n",
      "Accuracy: Training 0.948 / Validation = 0.944\n",
      "\n",
      "EPOCH 5 ...\n",
      "Accuracy: Training 0.950 / Validation = 0.948\n",
      "\n",
      "EPOCH 6 ...\n",
      "Accuracy: Training 0.961 / Validation = 0.957\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e767f398e4ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mKEEP_PROB\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "train_acc_epoch = []\n",
    "valid_acc_epoch = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):        \n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: KEEP_PROB})\n",
    "                \n",
    "        train_accuracy = evaluate(X_train, y_train)\n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        \n",
    "        epochs.append(i)\n",
    "        train_acc_epoch.append(train_accuracy)\n",
    "        valid_acc_epoch.append(validation_accuracy)\n",
    "        \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Accuracy: Training {:.3f} / Validation = {:.3f}\".format(train_accuracy, validation_accuracy))\n",
    "        print()\n",
    "        if validation_accuracy >= TARGET_ACCURACY:\n",
    "            break\n",
    "        \n",
    "    saver.save(sess, './traffic-v1')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
